---
title: "3"
format: pdf
editor: visual
---

## Lista 3

# Część I i II

## Zadanie 1

Napisz funkcję, która zwraca p-wartość w omówionym na wykładzie warunkowym

teście symetrii w przypadku tabeli 2 × 2.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(readr)
library(dplyr)
ankieta <- read.csv("ankieta.csv", sep=";", fileEncoding = "Latin2")
```

```{r, echo = TRUE, warning=FALSE, message=FALSE}
p <- function(n12, n21){
  part <- 0
  if(n12<(n12+n21)/2){
    for(i in 0:n12){
    part <- part + choose(n12+n21,i)*(1/2)^i*(1/2)^(n12+n21-i)
    }
    part <- 2*part
  }
  if(n12>(n12+n21)/2){
    for(i in 0:n12+n21){
    part <- part + choose(n12+n21,i)*(1/2)^i*(1/2)^(n12+n21-i)
    }
    part <- 2*part
  }
  if(n12==(n12+n21)/2){
    part <- 1
  }
  return(part)
}
```

## Zadanie 2

### Zadanie 2.1

```{r}
tabela <- matrix(c(1, 2, 5, 4), nrow = 2,
dimnames = list("Lek A" = c("Negatywna", "Pozytywna"),
"Lek B" = c("Negatywna", "Pozytywna")))
print(tabela)
#test McNemara
mcnemar.test(tabela, correct = TRUE)
```

### Zadanie 2.2

```{r, echo = FALSE, warning=FALSE, message=FALSE}
p(2,5)
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
binom.test(x = 2, n = 7, p = 0.5, alternative = "two.sided")$p.value
```

## Zadanie 3

Przeprowadź symulacje w celu porównania mocy testu $Z$ i testu $Z_0$ przedstawionych na wykładzie. Rozważ różne długości prób.

```{r, echo = FALSE, warning=FALSE, message=FALSE, dev="cairo_pdf"}
library(stats)
test_z <- function(n_matrix, p_matrix){
  D <- (n_matrix[1,2]-n_matrix[2,1])/sum(n_matrix)
  p1p <- sum(p_matrix[,1])
  pp1 <- sum(p_matrix[1,])
  sigma <- (p1p*(1-p1p) + pp1*(1-pp1) - 2*(p_matrix[1,1]*p_matrix[2,2] - p_matrix[1,2]*p_matrix[2,1]))/sum(n_matrix)
  Z <- D/sqrt(sigma)
  p <- 2*(1-pnorm(abs(Z)))
  return(p)
}
test_z0 <- function(n_matrix){
  n12 <- n_matrix[1,2]
  n21 <- n_matrix[2,1]
  Z0 <- (n12-n21)/sqrt(n12+n21)
  p <- 2*(1-pnorm(abs(Z0)))
  return(p)
}
simulate_power <- function(n){
  p1 <- 0.5
  n <- n
  Z_suma <- numeric(99)
  Z0_suma <- numeric(99)
  X <- rbinom(n=n, size=1, prob = p1)
  for(i in 1:1000){
    j <- 0
    for(p in seq(from = 0.01, to = 0.99, by=0.01)){
      j <- j+1
      repeat{
        Y <- rbinom(n,1,p)
        n_mat <- table(factor(X,levels=c(0,1)), factor(Y,levels=c(0,1)))
        if ((n_mat[1,2] + n_mat[2,1]) > 0) break 
      }
      p_mat <- n_mat/sum(n_mat)
      pz <- test_z(n_mat,p_mat)
      pz0 <- test_z0(n_mat)
      if(pz<0.05){
        Z_suma[j] <- Z_suma[j]+1
      }
      if(pz0<0.05){
        Z0_suma[j] <- Z0_suma[j]+1
      }
    }
  }
  p_values <- seq(from = 0.01, to = 0.99, by = 0.01)

  moc_Z <- Z_suma / 1000
  moc_Z0 <- Z0_suma / 1000
  
  plot(p_values, moc_Z, type = "l", col = "hotpink", lwd = 2,
       ylim = c(0, 1), xlab = "p", ylab = "Moc testu",
       main = paste0("Wykres mocy testów Z i Z0 dla n=",n))
  lines(p_values, moc_Z0, col = "darkseagreen", lwd = 2, lty = 2)
  legend("bottomright", legend = c("Test Z", "Test Z0"),
       col = c("hotpink", "darkseagreen"), lwd = 2, lty = c(1, 2))
}
simulate_power(30)
simulate_power(100)
simulate_power(300)
```

Widzimy, że dla mniejszych $n$ test $Z$ ma większą moc od testu $Z_0$. Dla większych $n$ moce testów zbiliżają sie do siebie oraz rosną, szczególnie wokół $p=0.5$.

## Zadanie 4

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
ankieta <- ankieta |>
mutate(
  CZY_ZADOW = case_when(
    PYT_2 %in% c(-2, -1) ~ "Niezadowolona",
    PYT_2 %in% c(2, 1) ~ "Zadowolona",
    TRUE ~ NA_character_
))
ankieta <- ankieta |> mutate(
  CZY_ZADOW2 = case_when(
    PYT_3 %in% c(-2, -1) ~ "Niezadowolona",
    PYT_3 %in% c(2, 1) ~ "Zadowolona",
    PYT_3 %in% c(0) ~ "-",
))
tabela <- table(ankieta$CZY_ZADOW, ankieta$CZY_ZADOW2)
mcnemar.test(tabela, correct = TRUE)
```

# Część III

## Zadanie 6

W pewnym badaniu porównywano skuteczność dwóch metod leczenia: Leczenie A to nowa procedura, a Leczenie B to stara procedura. Przeanalizuj dane przedstawione w Tabeli 3 (wyniki dla całej grupy pacjentów) oraz w Tabelach 4 i 5 (wyniki w podgrupach ze względu na dodatkową zmienną) i odpowiedz na pytanie, czy dla danych występuje paradoks Simpsona.

| Metoda     | Poprawa | Brak poprawy |
|------------|---------|--------------|
| Leczenie A | 117     | 104          |
| Leczenie B | 177     | 44           |

: Tabela 3: Dane dla całej grupy

| Metoda     | Poprawa | Brak poprawy |
|------------|---------|--------------|
| Leczenie A | 17      | 101          |
| Leczenie B | 2       | 36           |

: Tabela 4: Dane dla pacjentów z chorobami współistniejącymi.

| Metoda     | Poprawa | Brak poprawy |
|------------|---------|--------------|
| Leczenie A | 100     | 3            |
| Leczenie B | 175     | 8            |

: Tabela 5: Dane dla pacjentów bez chorób współistniejących.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
pa <- 117/(117+104)
pb <- 177/(177+44)
paz <- (17/(17++101))
pbz <- 2/(38)
pabez <- 100/103
pbbez <- 175/183
p <- matrix(c(pa,paz,pabez, pb,pbz,pbbez), byrow=TRUE, nrow=2)
rownames(p) <- c("A", "B")
colnames(p) <- c("wszyscy", "z chorobamu", "bez chorób")
p
```

Chociaż leczenie B "wygrywa" patrząc na całą grupę badanych, po podziale na grupy ze względu na obecność chorób współistniejących możemy zauważyć, że to leczenie A ma większy odsetek wyzdrowień.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
Az <- c(17, 101)
Bz <- c(2, 36)
Abez <- c(100, 3)
Bbez <- c(175, 8)
A <- Az+Abez
B <- Bz+Bbez
AB <- rbind(A,B)
p1 <- chisq.test(AB)$p.value
ABz <- rbind(Az, Bz)
p2 <- chisq.test(ABz)$p.value
ABbez <- rbind(Abez, Bbez)
p3 <- chisq.test(ABbez)$p.value
pvalues <- c(p1,p2,p3)
names(pvalues) <- c("wszyscy", "z chorobamu", "bez chorób")
pvalues
```

W przeprowadzonym teście niezależności $\chi ^2$ dla całej grupy p-value jest bardzo małe, więc odrzucamy hipotezę $H_0$ o niezależności. Jednak ten sam test wykonany osobno dla badanych grup - z chorobami współistniejącymi oraz bez chorób - w obu przypadkach daje p-value większą od poziomu istotności, a więc nie mamy podstaw do odrzucania hipotezy zerowej o niezależności zmiennych, to znaczy wyniku leczenia (poprawy) od przyjętego leczenia. To znaczy, że pozorny związek dla całej badanej grupy nie przekłada się na zalezność w podgrupach - a więc jest to klasyczny przypadek paradoksu Simpsona.

## Zadanie 7

Dla danych z listy 1, przyjmując za zmienną 1 zmiennaą CZY_KIER, za zmienną 2 – zmienną PYT_2 i za zmienną 3 – zmienną STAŻ, podaj interpretacje następujących modeli log-liniowych: \[1 3\], \[13\], \[1 2 3\], \[12 3\], \[12 13\] oraz \[1 23\].

\[1 3\] - zmienne CZY_KIER oraz STAŻ są niezależne,

\[13\] - zmienne CZY_KIER oraz STAŻ nie są niezależne,

\[1 2 3\] - zmienne CZY_KIER, PYT_2 oraz STAŻ są niezależne,

\[12 3\] - zmienne CZY_KIER i PYT_2 nie są niezależne, a zmienna STAŻ jest niezależna od nich obu,

\[12 13\] - zmienne CZY_KIER i PYT_2 nie są niezależne, CZY_KIER i STAŻ nie są niezalezne, a PYT_2 i STAŻ są warunkowo niezależne,

\[1 23\] - zmienna CZY_KIER jest niezależna od pozostałych dwóch, PYT_2 i STAŻ, które nie są od siebie niezależne.

# Część IV i V

## Zadanie 8

Przyjmując model log-liniowy \[123\] dla zmiennych opisanych w zadaniu 7 oszacuj prawdopobiebieństwa:

• że osoba pracująca na stanowisku kierowniczym jest zdecydowanie zadowolona ze szkoleń;

• że osoba o stażu pracy krótszym niż rok pracuje na stanowisku kierowniczym;

• że osoba o stażu pracy powyżej trzech lat nie pracuje na stanowisku kierowniczym.

Jakie byłyby oszacowania powyższych prawdopodobieństw przy założeniu modelu \[12 23\]?

Zaczynamy od modelu \[123\]:

```{r, echo = FALSE, warning=FALSE, message=FALSE}
tab1 <- as.data.frame(table(ankieta$CZY_KIER, ankieta$PYT_2, ankieta$STAŻ))
colnames(tab1) <- c("CZY_KIER", "PYT_2", "STAŻ", "Freq")
model_123 <- glm(Freq ~ CZY_KIER*PYT_2*STAŻ, data = tab1, family = poisson)
tab1$fitted <- fitted(model_123)

a <- subset(tab1, CZY_KIER == "Tak")
b <- subset(tab1, STAŻ == 1)
c <- subset(tab1, STAŻ == 3)
library(dplyr)
wynik_a <- a %>%
  group_by(PYT_2) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_b <- b %>%
  group_by(CZY_KIER) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_c <- c %>%
  group_by(CZY_KIER) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_a
wynik_b
wynik_c
```

Model \[123\] dobrze oszacował potrzebne prawdopodobieństwa (w 1. tabeli interesuje nas wiersz z odpowiedzią "2" na PYT_2, w 2. i 3. odpowiedź "Tak" w kolumnie CZY_KIER). Zarówno szacowane liczności jak i prawdopodobieństwa są równe dla modelu i danych.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
model_1223 <- glm(Freq ~ CZY_KIER * PYT_2 + PYT_2 * STAŻ, family = poisson, data = tab1)
tab1$fitted <- fitted(model_1223)

a <- subset(tab1, CZY_KIER == "Tak")
b <- subset(tab1, STAŻ == 1)
c <- subset(tab1, STAŻ == 3)
library(dplyr)
wynik_a <- a %>%
  group_by(PYT_2) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_b <- b %>%
  group_by(CZY_KIER) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_c <- c %>%
  group_by(CZY_KIER) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_a
wynik_b
wynik_c
```

Dla modelu \[12 23\] odpowiedź na pierwszy podpunkt się zgadza - wartości w danych są równe przewidywanym przez model. Jednak przy pytaniach, które łączą zmienne CZY_KIER oraz STAŻ (podpunkt 2. i 3.) model przeszacował wyniki z dla osób o krótkim stażu oraz niedoszacował odpowiedzi w dla osób o długim stażu - wynika to z braku powiązanie między tymi zmiennymi. Jak widzimy, złe dobranie modelu skutkuje złym oszacowaniem badanych prawdopodobieństw.

# Zadania dodatkowe

## Zadanie 2\*

Na podstawie danych z listy 1 dokonaj wyboru modelu rozważając uwzględnienie zmiennych PYT_1, PYT_2 i PŁEĆ w oparciu o:

• testy,

• kryterium AIC,

• kryterium BIC.

Będzimy roważać modele **\[1 2 3\]**, **\[12 13 23\]** oraz **\[123\]**.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
ankieta$PYT_1 <- factor(ankieta$PYT_1)
ankieta$PYT_2 <- factor(ankieta$PYT_2)
ankieta$PŁEĆ <- factor(ankieta$PŁEĆ)

df <- as.data.frame(xtabs(~ PYT_1 + PYT_2 + PŁEĆ, data = ankieta))
colnames(df) <- c("PYT_1", "PYT_2", "PŁEĆ", "Freq")

model_full <- glm(Freq ~ PYT_1 * PYT_2 * PŁEĆ, data = df, family = poisson)

model_12_13_23 <- glm(Freq ~ PYT_1 * PYT_2 + PYT_1 * PŁEĆ + PYT_2 * PŁEĆ, data = df, family = poisson)

model_indep <- glm(Freq ~ PYT_1 + PYT_2 + PŁEĆ, data = df, family = poisson)

anova(model_indep, model_12_13_23, model_full, test = "Chisq")
```

W tej analizie testujemy, czy model prostszy wystarcza ($H_0$), czy potrzebny jest model bardziej złożony ($H_1$). Testujemy, czy sensownie jest zmieniać model z \[1 2 3\] na \[12 13 23\] oraz \[12 13 23\] na \[123\]. Wykonujemy test istotności $\chi ^2$.

**Interpretacja:**

Model 1 (niezależność) jest zbyt prosty, ponieważ po dodaniu interakcji dwójkowych (Model 2) dopasowanie znacznie się poprawia (p \< 2e-16 więc odrzucamy $H_0$).

Model 3 (pełny) nie poprawia istotnie dopasowania względem Modelu 2 (p = 0.8326, nie ma podstaw do odrzucenia $H_0$), więc interakcja trójkowa nie jest potrzebna.

Ostateczny wybór: Model 2 – zawiera wszystkie istotne interakcje (dwójkowe), a jest prostszym modelem niż pełny.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
aic <- AIC(model_full, model_12_13_23, model_indep)
bic <- BIC(model_full, model_12_13_23, model_indep)
data.frame(
  Model = rownames(aic),
  AIC = aic$AIC,
  BIC = bic$BIC
)

```

Porównując **AIC** orac **BIC** widzimy, że dla obu kryteriów model \[12 13 23\] przymuje najmniejsze wartości, więc dla tego porównania jest najlepszy.

Zarówno testy chi-kwadrat, jak i kryteria AIC/BIC wskazują, że najlepszym modelem jest model z interakcjami dwójkowymi: `Freq ~ PYT_1*PYT_2 + PYT_1*PŁEĆ + PYT_2*PŁEĆ`, oznaczany jako **\[12 13 23\]**.
