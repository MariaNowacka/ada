---
format: pdf
editor: visual
---

## Lista 3

Celem niniejszego raportu jest pogłębiona analiza danych ankietowych z wykorzystaniem wybranych metod statystycznych. Zakres analizy obejmuje zarówno testy symetrii dla danych sparowanych, jak i symulacyjne porównanie mocy testów statystycznych, a także modelowanie zależności między zmiennymi za pomocą modeli log-liniowych.

W pierwszej części skupiłyśmy się na testach symetrii, w tym na implementacji warunkowego testu symetrii oraz jego zastosowaniu do rzeczywistych danych dotyczących skuteczności leków i oceny szkoleń. Druga część obejmuje porównanie mocy dwóch testów przy różnych rozmiarach prób, co pozwala ocenić ich efektywność w różnych warunkach badawczych.

W dalszej części przeanalizowałyśmy wybrane zbiory danych z wcześniejszych list zadań, weryfikując hipotezy o symetrii rozkładu odpowiedzi oraz przeprowadzając testy związane z możliwymi zmianami opinii respondentów w czasie. W kolejnych sekcjach zastosowałyśmy modele log-liniowe do opisu zależności między zmiennymi takimi jak stanowisko kierownicze, opinia o szkoleniach i staż pracy, uwzględniając również alternatywne modele oraz ich porównania za pomocą kryteriów AIC i BIC.

Raport kończy analiza zjawiska paradoksu Simpsona na podstawie danych dotyczących skuteczności dwóch metod leczenia oraz zadania dodatkowe związane z dokładnymi testami symetrii i wyborem najlepszego modelu dla wskazanych zmiennych.

# Część I i II

## Zadanie 1

Napisz funkcję, która zwraca p-wartość w omówionym na wykładzie warunkowym

teście symetrii w przypadku tabeli 2 × 2.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(readr)
library(dplyr)
ankieta <- read.csv("ankieta.csv", sep=";", fileEncoding = "Latin2")
```

```{r, echo = TRUE, warning=FALSE, message=FALSE}
p <- function(n12, n21){
  part <- 0
  if(n12<(n12+n21)/2){
    for(i in 0:n12){
    part <- part + choose(n12+n21,i)*(1/2)^i*(1/2)^(n12+n21-i)
    }
    part <- 2*part
  }
  if(n12>(n12+n21)/2){
    for(i in 0:n12+n21){
    part <- part + choose(n12+n21,i)*(1/2)^i*(1/2)^(n12+n21-i)
    }
    part <- 2*part
  }
  if(n12==(n12+n21)/2){
    part <- 1
  }
  return(part)
}
```

## Zadanie 2

### Zadanie 2.1

```{r}
tabela <- matrix(c(1, 2, 5, 4), nrow = 2,
dimnames = list("Lek A" = c("Negatywna", "Pozytywna"),
"Lek B" = c("Negatywna", "Pozytywna")))
print(tabela)
#test McNemara
mcnemar.test(tabela, correct = TRUE)
```

### Zadanie 2.2

```{r, echo = FALSE, warning=FALSE, message=FALSE}
p(2,5)
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
binom.test(x = 2, n = 7, p = 0.5, alternative = "two.sided")$p.value
```

## Zadanie 3

Przeprowadź symulacje w celu porównania mocy testu $Z$ i testu $Z_0$ przedstawionych na wykładzie. Rozważ różne długości prób.

```{r, echo = FALSE, warning=FALSE, message=FALSE, dev="cairo_pdf"}
library(stats)
test_z <- function(n_matrix, p_matrix){
  D <- (n_matrix[1,2]-n_matrix[2,1])/sum(n_matrix)
  p1p <- sum(p_matrix[,1])
  pp1 <- sum(p_matrix[1,])
  sigma <- (p1p*(1-p1p) + pp1*(1-pp1) - 2*(p_matrix[1,1]*p_matrix[2,2] - p_matrix[1,2]*p_matrix[2,1]))/sum(n_matrix)
  Z <- D/sqrt(sigma)
  p <- 2*(1-pnorm(abs(Z)))
  return(p)
}
test_z0 <- function(n_matrix){
  n12 <- n_matrix[1,2]
  n21 <- n_matrix[2,1]
  Z0 <- (n12-n21)/sqrt(n12+n21)
  p <- 2*(1-pnorm(abs(Z0)))
  return(p)
}
simulate_power <- function(n){
  p1 <- 0.5
  n <- n
  Z_suma <- numeric(99)
  Z0_suma <- numeric(99)
  X <- rbinom(n=n, size=1, prob = p1)
  for(i in 1:1000){
    j <- 0
    for(p in seq(from = 0.01, to = 0.99, by=0.01)){
      j <- j+1
      repeat{
        Y <- rbinom(n,1,p)
        n_mat <- table(factor(X,levels=c(0,1)), factor(Y,levels=c(0,1)))
        if ((n_mat[1,2] + n_mat[2,1]) > 0) break 
      }
      p_mat <- n_mat/sum(n_mat)
      pz <- test_z(n_mat,p_mat)
      pz0 <- test_z0(n_mat)
      if(pz<0.05){
        Z_suma[j] <- Z_suma[j]+1
      }
      if(pz0<0.05){
        Z0_suma[j] <- Z0_suma[j]+1
      }
    }
  }
  p_values <- seq(from = 0.01, to = 0.99, by = 0.01)

  moc_Z <- Z_suma / 1000
  moc_Z0 <- Z0_suma / 1000
  
  plot(p_values, moc_Z, type = "l", col = "hotpink", lwd = 2,
       ylim = c(0, 1), xlab = "p", ylab = "Moc testu",
       main = paste0("Wykres mocy testów Z i Z0 dla n=",n))
  lines(p_values, moc_Z0, col = "darkseagreen", lwd = 2, lty = 2)
  legend("bottomright", legend = c("Test Z", "Test Z0"),
       col = c("hotpink", "darkseagreen"), lwd = 2, lty = c(1, 2))
}
simulate_power(30)
simulate_power(100)
simulate_power(300)
```

Widzimy, że dla mniejszych $n$ test $Z$ ma większą moc od testu $Z_0$. Dla większych $n$ moce testów zbiliżają sie do siebie oraz rosną, szczególnie wokół $p=0.5$.

## Zadanie 4

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
ankieta <- ankieta |>
mutate(
  CZY_ZADOW = case_when(
    PYT_2 %in% c(-2, -1) ~ "Niezadowolona",
    PYT_2 %in% c(2, 1) ~ "Zadowolona",
    TRUE ~ NA_character_
))
ankieta <- ankieta |> mutate(
  CZY_ZADOW2 = case_when(
    PYT_3 %in% c(-2, -1) ~ "Niezadowolona",
    PYT_3 %in% c(2, 1) ~ "Zadowolona",
    PYT_3 %in% c(0) ~ "-",
))
tabela <- table(ankieta$CZY_ZADOW, ankieta$CZY_ZADOW2)
mcnemar.test(tabela, correct = TRUE)
```

## Zadanie 5

Zadanie 5 dotyczy oceny skuteczności działań wdrożonych w firmie mających na celu poprawę komfortu pracy oraz efektywności wykorzystania wiedzy zdobytej na szkoleniach. W tym celu przeprowadzono badanie ankietowe w dwóch okresach: przed wdrożeniem zmian oraz po ich wprowadzeniu. Respondenci zostali poproszeni o ocenę podejścia firmy do umożliwiania praktycznego wdrażania zdobytej wiedzy.

Zebrane dane zostały przedstawione w postaci tablicy dwudzielczej, w której odpowiedzi z pierwszego okresu zostały zestawione z odpowiedziami z drugiego okresu. Oceny przyjmują wartości od -2 do 2, gdzie wyższe wartości oznaczają bardziej pozytywną ocenę. Celem analizy jest weryfikacja hipotezy, że rozkład odpowiedzi w obu okresach jest symetryczny, co odpowiadałoby brakowi zmiany w ocenach.

```{r, echo = FALSE, warning=FALSE}
dane <- matrix(c(
  10,  2,  1,  1,  0,
   0, 15,  1,  1,  0,
   1,  1, 32,  6,  0,
   0,  0,  1, 96,  3,
   1,  1,  0,  1, 26
), nrow = 5, byrow = TRUE)

rownames(dane) <- colnames(dane) <- c("-2", "-1", "0", "1", "2")
dane

```

```{r, echo=FALSE}
bowker_test <- mcnemar.test(dane, correct = TRUE)
bowker_test
```

W celu weryfikacji hipotezy o symetrii odpowiedzi w dwóch okresach badania zastosowałyśmy rozszerzoną wersję testu McNemara, czyli test Bowkera, odpowiednią dla tablic większych niż 2×2. W analizie wykorzystano funkcję mcnemar.test(), jednak test zwrócił wartość statystyki NaN oraz p-value = NA. Taki wynik jest zgodny z teoretycznymi założeniami testu Bowkera, który opiera się na porównaniu częstości odpowiedzi w pozycjach symetrycznych względem głównej przekątnej (nij vs nji). W przypadku, gdy suma tych par (tj. nij + nji) wynosi zero, powstaje niedozwolona operacja dzielenia przez zero w obliczeniach statystyki testowej.

Z tego względu klasyczny test Bowkera nie może być zastosowany w tej sytuacji i posłużymy się alternatywnym podejściem, testem LW, który lepiej radzi sobie w obecności zerowych komórek poza przekątną.

```{r, echo=FALSE}

test_LW <- function(tablica) {
  I <- nrow(tablica)
  n <- sum(tablica)
  G2 <- 0
  
  for (i in 1:I) {
    for (j in 1:I) {
      if (i != j && tablica[i, j] > 0) {
        nij <- tablica[i, j]
        nji <- tablica[j, i]
        p_hat <- (nij + nji) / (2 * n)
        G2 <- G2 + 2 * nij * log(nij / (n * p_hat))
      }
    }
  }
  
  r <- I * (I - 1) / 2
  p_val <- 1 - pchisq(G2, df = r)
  
  list(
    statistic = G2,
    df = r,
    p.value = p_val,
    method = "Test LW",
    data.name = deparse(substitute(tablica))
  )
}

test_LW(dane)

```

**Wnioski** P-value wynosi 0.206, co jest większe od przyjętego poziomu istotności alpha = 0.05. Oznacza to, że brak podstaw do odrzucenia hipotezy o symetrii rozkładu odpowiedzi w dwóch badanych okresach. Nie stwierdzono istotnej statystycznie zmiany oceny podejścia firmy do umożliwiania wdrażania wiedzy zdobytej na szkoleniach. Odpowiedzi respondentów przed i po wdrożeniu działań poprawiających komfort pracy można uznać za zgodne z modelem symetrii. \# Część III

## Zadanie 6

W pewnym badaniu porównywano skuteczność dwóch metod leczenia: Leczenie A to nowa procedura, a Leczenie B to stara procedura. Przeanalizuj dane przedstawione w Tabeli 3 (wyniki dla całej grupy pacjentów) oraz w Tabelach 4 i 5 (wyniki w podgrupach ze względu na dodatkową zmienną) i odpowiedz na pytanie, czy dla danych występuje paradoks Simpsona.

| Metoda     | Poprawa | Brak poprawy |
|------------|---------|--------------|
| Leczenie A | 117     | 104          |
| Leczenie B | 177     | 44           |

: Tabela 3: Dane dla całej grupy

| Metoda     | Poprawa | Brak poprawy |
|------------|---------|--------------|
| Leczenie A | 17      | 101          |
| Leczenie B | 2       | 36           |

: Tabela 4: Dane dla pacjentów z chorobami współistniejącymi.

| Metoda     | Poprawa | Brak poprawy |
|------------|---------|--------------|
| Leczenie A | 100     | 3            |
| Leczenie B | 175     | 8            |

: Tabela 5: Dane dla pacjentów bez chorób współistniejących.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
pa <- 117/(117+104)
pb <- 177/(177+44)
paz <- (17/(17++101))
pbz <- 2/(38)
pabez <- 100/103
pbbez <- 175/183
p <- matrix(c(pa,paz,pabez, pb,pbz,pbbez), byrow=TRUE, nrow=2)
rownames(p) <- c("A", "B")
colnames(p) <- c("wszyscy", "z chorobamu", "bez chorób")
p
```

Chociaż leczenie B "wygrywa" patrząc na całą grupę badanych, po podziale na grupy ze względu na obecność chorób współistniejących możemy zauważyć, że to leczenie A ma większy odsetek wyzdrowień.

```{r, echo = FALSE, warning=FALSE, message=FALSE}
Az <- c(17, 101)
Bz <- c(2, 36)
Abez <- c(100, 3)
Bbez <- c(175, 8)
A <- Az+Abez
B <- Bz+Bbez
AB <- rbind(A,B)
p1 <- chisq.test(AB)$p.value
ABz <- rbind(Az, Bz)
p2 <- chisq.test(ABz)$p.value
ABbez <- rbind(Abez, Bbez)
p3 <- chisq.test(ABbez)$p.value
pvalues <- c(p1,p2,p3)
names(pvalues) <- c("wszyscy", "z chorobamu", "bez chorób")
pvalues
```

W przeprowadzonym teście niezależności $\chi ^2$ dla całej grupy p-value jest bardzo małe, więc odrzucamy hipotezę $H_0$ o niezależności. Jednak ten sam test wykonany osobno dla badanych grup - z chorobami współistniejącymi oraz bez chorób - w obu przypadkach daje p-value większą od poziomu istotności, a więc nie mamy podstaw do odrzucania hipotezy zerowej o niezależności zmiennych, to znaczy wyniku leczenia (poprawy) od przyjętego leczenia. To znaczy, że pozorny związek dla całej badanej grupy nie przekłada się na zalezność w podgrupach - a więc jest to klasyczny przypadek paradoksu Simpsona.

## Zadanie 7

Dla danych z listy 1, przyjmując za zmienną 1 zmiennaą CZY_KIER, za zmienną 2 – zmienną PYT_2 i za zmienną 3 – zmienną STAŻ, podaj interpretacje następujących modeli log-liniowych: \[1 3\], \[13\], \[1 2 3\], \[12 3\], \[12 13\] oraz \[1 23\].

\[1 3\] - zmienne CZY_KIER oraz STAŻ są niezależne,

\[13\] - zmienne CZY_KIER oraz STAŻ nie są niezależne,

\[1 2 3\] - zmienne CZY_KIER, PYT_2 oraz STAŻ są niezależne,

\[12 3\] - zmienne CZY_KIER i PYT_2 nie są niezależne, a zmienna STAŻ jest niezależna od nich obu,

\[12 13\] - zmienne CZY_KIER i PYT_2 nie są niezależne, CZY_KIER i STAŻ nie są niezalezne, a PYT_2 i STAŻ są warunkowo niezależne,

\[1 23\] - zmienna CZY_KIER jest niezależna od pozostałych dwóch, PYT_2 i STAŻ, które nie są od siebie niezależne.

# Część IV i V

## Zadanie 8

Przyjmując model log-liniowy \[123\] dla zmiennych opisanych w zadaniu 7 oszacuj prawdopobiebieństwa:

• że osoba pracująca na stanowisku kierowniczym jest zdecydowanie zadowolona ze szkoleń;

• że osoba o stażu pracy krótszym niż rok pracuje na stanowisku kierowniczym;

• że osoba o stażu pracy powyżej trzech lat nie pracuje na stanowisku kierowniczym.

Jakie byłyby oszacowania powyższych prawdopodobieństw przy założeniu modelu \[12 23\]?

Zaczynamy od modelu \[123\]:

```{r, echo = FALSE, warning=FALSE, message=FALSE}
tab1 <- as.data.frame(table(ankieta$CZY_KIER, ankieta$PYT_2, ankieta$STAŻ))
colnames(tab1) <- c("CZY_KIER", "PYT_2", "STAŻ", "Freq")
model_123 <- glm(Freq ~ CZY_KIER*PYT_2*STAŻ, data = tab1, family = poisson)
tab1$fitted <- fitted(model_123)

a <- subset(tab1, CZY_KIER == "Tak")
b <- subset(tab1, STAŻ == 1)
c <- subset(tab1, STAŻ == 3)
library(dplyr)
wynik_a <- a %>%
  group_by(PYT_2) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_b <- b %>%
  group_by(CZY_KIER) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_c <- c %>%
  group_by(CZY_KIER) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_a
wynik_b
wynik_c
```

Model \[123\] dobrze oszacował potrzebne prawdopodobieństwa (w 1. tabeli interesuje nas wiersz z odpowiedzią "2" na PYT_2, w 2. i 3. odpowiedź "Tak" w kolumnie CZY_KIER). Zarówno szacowane liczności jak i prawdopodobieństwa są równe dla modelu i danych.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
model_1223 <- glm(Freq ~ CZY_KIER * PYT_2 + PYT_2 * STAŻ, family = poisson, data = tab1)
tab1$fitted <- fitted(model_1223)

a <- subset(tab1, CZY_KIER == "Tak")
b <- subset(tab1, STAŻ == 1)
c <- subset(tab1, STAŻ == 3)
library(dplyr)
wynik_a <- a %>%
  group_by(PYT_2) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_b <- b %>%
  group_by(CZY_KIER) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_c <- c %>%
  group_by(CZY_KIER) %>%
  summarise(freq_sum = sum(Freq),
            fitted_sum = sum(fitted)) %>%
  mutate(p_dane = freq_sum / sum(freq_sum),
         p_model = fitted_sum / sum(fitted_sum))
wynik_a
wynik_b
wynik_c
```

Dla modelu \[12 23\] odpowiedź na pierwszy podpunkt się zgadza - wartości w danych są równe przewidywanym przez model. Jednak przy pytaniach, które łączą zmienne CZY_KIER oraz STAŻ (podpunkt 2. i 3.) model przeszacował wyniki z dla osób o krótkim stażu oraz niedoszacował odpowiedzi w dla osób o długim stażu - wynika to z braku powiązanie między tymi zmiennymi. Jak widzimy, złe dobranie modelu skutkuje złym oszacowaniem badanych prawdopodobieństw.

## Zadanie 9

Dla danych wskazanych w zadaniu 7 zweryfikuj następujące hipotezy:

\- Zmienne losowe **CZY_KIER**, **PYT_2** i **STAŻ** są wzajemnie niezależne,

\- Zmienna losowa **PYT_2** jest niezależna od pary zmiennych **CZY_KIER** i **STAŻ**,

\- Zmienna losowa **PYT_2** jest niezależna od zmiennej **CZY_KIER**, przy ustalonej wartości zmiennej **STAŻ**.

Celem zadania jest weryfikacja zależności pomiędzy trzema zmiennymi kategorycznymi: CZY_KIER (czy osoba pracuje na stanowisku kierowniczym), PYT_2 (ocena szkolenia) oraz STAŻ (długość stażu pracy). Analiza oparta jest na modelach log-liniowych, które umożliwiają badanie zarówno pełnej niezależności pomiędzy wszystkimi zmiennymi, jak i zależności marginalnych oraz warunkowych.

```{r, echo=FALSE, warning=FALSE}
library(MASS)

CZY_KIER <- ankieta$CZY_KIER
PYT_2 <- ankieta$PYT_2
STAŻ <- ankieta$STAŻ
df <- data.frame(CZY_KIER, PYT_2, STAŻ)

df_aggr <- as.data.frame(table(df))
colnames(df_aggr) <- c("CZY_KIER", "PYT_2", "STAZ", "LICZBA")
```

a)  Wzajemna niezależność \[1\]\[2\]\[3\]

Rozważmy 3 nadmodele, np. \[12 23\], \[13 23\], \[123\]

```{r, echo=FALSE}
M0 <- glm(LICZBA ~ CZY_KIER + PYT_2 + STAZ, family = poisson, data = df_aggr)

M1 <- glm(LICZBA ~ CZY_KIER * PYT_2 + PYT_2 * STAZ, family = poisson, data = df_aggr)
anova(M0, M1, test = "Chisq")

M2 <- glm(LICZBA ~ CZY_KIER * STAZ + PYT_2 * STAZ, family = poisson, data = df_aggr)
anova(M0, M2, test = "Chisq")

M3 <- glm(LICZBA ~ CZY_KIER * PYT_2 * STAZ, family = poisson, data = df_aggr)
anova(M0, M3, test = "Chisq")
```

1.  \[12 23\] vs \[1\]\[2\]\[3\]

-   Deviance: 26.601
-   df: 9
-   p-value: 0.001628

2.  \[13 23\] vs \[1\]\[2\]\[3\]

-   Deviance: 37.362
-   df: 8
-   p-value: 9.871e-06

3.  \[123\] vs \[1\]\[2\]\[3\]

-   Deviance: 42.242
-   df: 17
-   p-value: 0.0006187

Ponieważ we wszystkich porównaniach p-value są mniejsze niż 0.05, odrzucamy hipotezę zerową o wzajemnej niezależności zmiennych. Wnioskujemy, że zmienne te nie są wzajemnie niezależne – występują między nimi istotne statystycznie zależności.

b)  Zmienna PYT_2 jest niezależna od pary zmiennych CZY_KIER i STAŻ, czyli model ma postać log-liniową: \[2 13\]

```{r, echo=FALSE}

M0_b <- glm(LICZBA ~ PYT_2 + CZY_KIER * STAZ,
            family = poisson, data = df_aggr)

M1_b1 <- glm(LICZBA ~ CZY_KIER * PYT_2 + PYT_2 * STAZ,
             family = poisson, data = df_aggr)
anova(M0_b, M1_b1, test = "Chisq")

M1_b2 <- glm(LICZBA ~ CZY_KIER * STAZ + PYT_2 * STAZ,
             family = poisson, data = df_aggr)
anova(M0_b, M1_b2, test = "Chisq")

M1_b3 <- glm(LICZBA ~ CZY_KIER * PYT_2 * STAZ,
             family = poisson, data = df_aggr)
anova(M0_b, M1_b3, test = "Chisq")

```

1.  \[12 23\] vs \[2 13\]

-   Deviance: 7.5105
-   df: 7
-   p-value: 0.3777 → brak podstaw do odrzucenia hipotezy zerowej

2.  \[13 23\] vs \[2 13\]

-   Deviance: 18.272
-   df: 6
-   p-value: 0.0056 → odrzucamy hipoteze zerową

3.  \[123\] vs \[2 13\]

-   Deviance: 23.152
-   df: 10
-   p-value: 0.08096 → brak podstaw do odrzucenia hipotezy zerowej

Na podstawie porównań modelu zakładającego niezależność zmiennej PYT_2 od pary zmiennych CZY_KIER i STAŻ z trzema bardziej złożonymi nadmodelami, można stwierdzić, że: - tylko w jednym przypadku (model \[13 23\]) uzyskano istotną statystycznie poprawę dopasowania (p = 0.0056 \< 0.05), - natomiast dla modeli \[12 23\] oraz \[123\] wartości p były większe niż 0.05, co oznacza brak istotnej poprawy dopasowania.

Nie ma wystarczających statystycznych podstaw do odrzucenia hipotezy, że zmienna PYT_2 jest niezależna od pary zmiennych CZY_KIER i STAŻ na poziomie istotności α = 0.05.

c)  \[13 23\]

```{r, echo=FALSE}

M0_c <- glm(LICZBA ~ CZY_KIER * STAZ + PYT_2 * STAZ,
            family = poisson, data = df_aggr)


M1_c1 <- glm(LICZBA ~ CZY_KIER * PYT_2 + PYT_2 * STAZ + CZY_KIER * STAZ,
             family = poisson, data = df_aggr)

anova(M0_c, M1_c1, test = "Chisq")


M1_c2 <- glm(LICZBA ~ CZY_KIER * PYT_2 * STAZ,
             family = poisson, data = df_aggr)

anova(M0_c, M1_c2, test = "Chisq")

```

1.  \[12 13 23\] vs \[12 23\]

-   Deviance: 3.2832
-   df: 3
-   p-value: 0.35 → brak podstaw do odrzucenia hipotezy zerowej

2.  \[123\] vs \[1 23\]

-   Deviance: 4.88
-   df: 9
-   p-value: 0.8446 → brak podstaw do odrzucenia hipotezy zerowej

W obu przypadkach wartości p są znacznie większe od przyjętego poziomu istotności α = 0.05, co oznacza, że nie ma statystycznych podstaw do odrzucenia hipotezy zerowej. Innymi słowy, nie stwierdzono istotnych zależności pomiędzy odpowiedziami na pytanie PYT_2 a statusem kierowniczym, jeżeli uwzględnimy staż pracy.

\# Zadania dodatkowe

## Zadanie 1\*

W przypadku zadania 5 występuje problem z zastosowaniem testu Bowkera ze względu na występowanie zer na określonych miejscach w tabeli z danymi.Zastosuj w tym przypadku dokładny test symetrii i opisz, w jaki sposób wyznaczana jest wartość poziomu krytycznego w tym teście3

Dlatego, że w macierzy mamy obecność zer, to test Bowkera jest niewłaściwy. Stosujemy test dokładny, który sprawdza, czy odpowiedzi są symetryczne względem przekątnej.

```{r, echo=FALSE}
mat <- matrix(c(
  10, 2, 1, 1, 0,
  0,15, 1, 1, 0,
  1, 1,32, 6, 0,
  0, 0, 1,96, 3,
  1, 1, 0, 1,26
), nrow=5, byrow=TRUE)

rownames(mat) <- colnames(mat) <- c("-2", "-1", "0", "1", "2")
mat

#Testujemy -> H0: Macierz jest symetryczna względem przekątnej.

# statystyka testowa. To daje całkowitą „niesymetryczność” macierzy — im większa suma, tym większe odchylenie od symetrii.
test_statistic <- function(m) {
  sum(abs(m[lower.tri(m)] - t(m)[lower.tri(m)]))
}

w <- test_statistic(mat)

#Chcemy porównać obserwowaną niesymetryczność z tym, co mogłoby się zdarzyć przypadkowo, gdyby naprawdę nie było żadnej zmiany (czyli zakładamy, że tabela powinna być symetryczna — hipoteza zerowa).

set.seed(123)
n <- 10000
sim_stats <- numeric(n)

for (i in 1:n) {
  m_sim <- mat
  for (r in 1:4) {
    for (c in (r+1):5) {
      total <- mat[r, c] + mat[c, r]
      draw <- rbinom(1, total, 0.5)
      m_sim[r, c] <- draw
      m_sim[c, r] <- total - draw
    }
  }
  sim_stats[i] <- test_statistic(m_sim)
}

p_value <- mean(sim_stats >= w)
p_value
```

W przypadku, gdy klasyczny test Bowkera nie może zostać zastosowany ze względu na obecność zer w tabeli kontyngencji, stosuje się tzw. dokładny test symetrii. Test ten opiera się na permutacyjnym podejściu do weryfikacji hipotezy zerowej mówiącej, że badana tablica jest symetryczna względem głównej przekątnej.

W tym podejściu najpierw obliczana jest statystyka testowa W, która mierzy całkowitą niesymetryczność tabeli — w tym przypadku jest to suma bezwzględnych różnic pomiędzy odpowiadającymi sobie elementami symetrycznymi względem przekątne. Następnie, zakładając prawdziwość hipotezy zerowej (czyli że rozkład odpowiedzi jest symetryczny), przeprowadza się symulację wielu możliwych losowych, symetrycznych tablic. W każdej iteracji dla każdej pary komórek symetrycznych (i,j) i (j,i) rozdziela się ich łączną sumę na dwa składniki zgodnie z rozkładem dwumianowym o parametrze p = 0.5 (czyli zakładając równą szansę odpowiedzi po każdej stronie symetrii). Dla każdej takiej zasymulowanej tablicy oblicza się wartość statystyki testowej.

P-value wynosi 0.2948 co jest większe niż 0.05, a więc nie mamy podstaw do odrzucenia hipotezy symetrii. Na podstawie tego testu nie ma podstaw, żeby twierdzić, że opinie pracowników zmieniły się po działaniach firmy.

## Zadanie 2\*

Na podstawie danych z listy 1 dokonaj wyboru modelu rozważając uwzględnienie zmiennych PYT_1, PYT_2 i PŁEĆ w oparciu o:

• testy,

• kryterium AIC,

• kryterium BIC.

Będzimy roważać modele **\[1 2 3\]**, **\[12 13 23\]** oraz **\[123\]**.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
ankieta$PYT_1 <- factor(ankieta$PYT_1)
ankieta$PYT_2 <- factor(ankieta$PYT_2)
ankieta$PŁEĆ <- factor(ankieta$PŁEĆ)

df <- as.data.frame(xtabs(~ PYT_1 + PYT_2 + PŁEĆ, data = ankieta))
colnames(df) <- c("PYT_1", "PYT_2", "PŁEĆ", "Freq")

model_full <- glm(Freq ~ PYT_1 * PYT_2 * PŁEĆ, data = df, family = poisson)

model_12_13_23 <- glm(Freq ~ PYT_1 * PYT_2 + PYT_1 * PŁEĆ + PYT_2 * PŁEĆ, data = df, family = poisson)

model_indep <- glm(Freq ~ PYT_1 + PYT_2 + PŁEĆ, data = df, family = poisson)

anova(model_indep, model_12_13_23, model_full, test = "Chisq")
```

W tej analizie testujemy, czy model prostszy wystarcza ($H_0$), czy potrzebny jest model bardziej złożony ($H_1$). Testujemy, czy sensownie jest zmieniać model z \[1 2 3\] na \[12 13 23\] oraz \[12 13 23\] na \[123\]. Wykonujemy test istotności $\chi ^2$.

**Interpretacja:**

Model 1 (niezależność) jest zbyt prosty, ponieważ po dodaniu interakcji dwójkowych (Model 2) dopasowanie znacznie się poprawia (p \< 2e-16 więc odrzucamy $H_0$).

Model 3 (pełny) nie poprawia istotnie dopasowania względem Modelu 2 (p = 0.8326, nie ma podstaw do odrzucenia $H_0$), więc interakcja trójkowa nie jest potrzebna.

Ostateczny wybór: Model 2 – zawiera wszystkie istotne interakcje (dwójkowe), a jest prostszym modelem niż pełny.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
aic <- AIC(model_full, model_12_13_23, model_indep)
bic <- BIC(model_full, model_12_13_23, model_indep)
data.frame(
  Model = rownames(aic),
  AIC = aic$AIC,
  BIC = bic$BIC
)

```

Porównując **AIC** orac **BIC** widzimy, że dla obu kryteriów model \[12 13 23\] przymuje najmniejsze wartości, więc dla tego porównania jest najlepszy.

Zarówno testy chi-kwadrat, jak i kryteria AIC/BIC wskazują, że najlepszym modelem jest model z interakcjami dwójkowymi: `Freq ~ PYT_1*PYT_2 + PYT_1*PŁEĆ + PYT_2*PŁEĆ`, oznaczany jako **\[12 13 23\]**.
